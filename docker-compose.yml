services:
  redis:
    image: redis:7.2-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 10

  guardrails:
    build: .
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
    environment:
      GR_POLICY_PATH: /app/configs/policy.yaml
      GR_REDIS_URL: redis://redis:6379/0
      GR_RUNTIME_MODE: cpu
      GR_CPU_DEVICE: auto
      GR_MODEL_DIR: /models
      GR_OFFLINE_MODE: ${GR_OFFLINE_MODE:-false}
    ports:
      - "8080:8080"
    volumes:
      - ${GR_MODELS_DIR:-./.models}:/models:ro
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8080/health').read()"]
      interval: 5s
      timeout: 3s
      retries: 120
      start_period: 180s

  pytriton:
    build:
      context: .
      dockerfile: Dockerfile.pytriton
    environment:
      GR_PYTRITON_MODEL_NAME: gliner
      GR_PYTRITON_MODEL_REF: urchade/gliner_multi-v2.1
      GR_PYTRITON_DEVICE: cuda
      GR_PYTRITON_MAX_BATCH_SIZE: "32"
      GR_MODEL_DIR: /models
      GR_OFFLINE_MODE: ${GR_OFFLINE_MODE:-false}
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    volumes:
      - ${GR_MODELS_DIR:-./.models}:/models:ro
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/v2/health/ready').read()"]
      interval: 5s
      timeout: 3s
      retries: 120
      start_period: 180s
    gpus: all
    profiles: ["cuda"]

  guardrails-cuda:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
    environment:
      GR_POLICY_PATH: /app/configs/policy.yaml
      GR_REDIS_URL: redis://redis:6379/0
      GR_RUNTIME_MODE: cuda
      GR_PYTRITON_URL: pytriton:8000
      GR_PYTRITON_MODEL_NAME: gliner
      GR_PYTRITON_INIT_TIMEOUT_S: "30"
      GR_PYTRITON_INFER_TIMEOUT_S: "60"
      GR_MODEL_DIR: /models
      GR_OFFLINE_MODE: ${GR_OFFLINE_MODE:-false}
    ports:
      - "8081:8080"
    volumes:
      - ${GR_MODELS_DIR:-./.models}:/models:ro
    depends_on:
      redis:
        condition: service_healthy
      pytriton:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8080/health').read()"]
      interval: 5s
      timeout: 3s
      retries: 120
      start_period: 180s
    profiles: ["cuda"]

  integration-tests:
    build: .
    command: ["pytest", "tests/integration", "-q"]
    environment:
      GUARDRAILS_BASE_URL: http://guardrails:8080
    depends_on:
      guardrails:
        condition: service_healthy
    profiles: ["test"]
